#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
#  K E N D A P Y . B A C Y _ V E R I
#  read output generated by veri step, find common observations
#
#  2021.6 L.Scheck 

from __future__ import absolute_import, division, print_function

import os, sys, subprocess, glob, tempfile, re, argparse
from datetime import datetime, timedelta
import numpy as np

import matplotlib
matplotlib.use('Agg')
from matplotlib import pyplot as plt
from matplotlib.lines import Line2D

from kendapy.ekf        import Ekf
from kendapy.bacy_utils import to_timedelta, to_datetime, t2str, str2t, add_branch, common_subset
from kendapy.bacy_exp   import BacyExp


#----------------------------------------------------------------------------------------------------------------------
def define_parser() :

    parser = argparse.ArgumentParser(description="Generate basic observation space plots for bacy experiments")

    parser.add_argument( '-s', '--start-time',       dest='start_time', default=None,  help='cycling start time' )
    parser.add_argument( '-e', '--end-time',         dest='end_time'  , default=None,  help='cycling end   time' )
    parser.add_argument( '-O', '--obstype',          dest='obstype',    default='SYNOP', help='observation type, e.g. SYNOP' )
    parser.add_argument( '-V', '--varname',          dest='varname',    default='T2M',   help='variable name' )

    # output options
    parser.add_argument( '-o', '--output-path', dest='output_path',        default=None,              help='output path' )
    parser.add_argument( '-i', '--image-type',  dest='image_type',         default='png',             help='[ png | eps | pdf ... ]' )
    parser.add_argument(       '--dpi',         dest='dpi',                default=100, type=int,     help='dots per inch for pixel graphics (default: 100)' )
    parser.add_argument(       '--figsize',     dest='figsize',            default='5,4',             help='<figure width>,<figure height> [inch]' )
    parser.add_argument(       '--colors',      dest='colors',             default=None,              help='comma-separated list of colors (e.g. "r,#ff0000,pink")' )
    parser.add_argument(       '--legloc',      dest='legloc',             default='best',            help='location of legend (default="best", see matplotlib documentation, "outside"=to the right of plot window)' )

    parser.add_argument( '-v', '--verbose',     dest='verbose', action='store_true',  help='be extremely verbose' )

    parser.add_argument( 'experiments', metavar='<experiment path(s)>', help='path(s) to experiment(s)', nargs='*' )

    return parser


#----------------------------------------------------------------------------------------------------------------------
def get_veri_data( experiments, obstype, start_time=None, end_time=None, add_vars=None, **filter ) :
    
    # convert input to list of BacyExp structures, if necessary
    if type(experiments) == list :
        xps = []
        for xp_ in experiments :
            if type(xp_) == BacyExp :
                xps.append(xp_)
            else :
                xps.append( BacyExp(xp_) )# created from path
        n_exps = len(xps)
    else :
        if type(experiments) == BacyExp :
            xp = experiments
        else :
            xp = BacyExp(experiments) # created from path
        xps = [xp]
        n_exps = 1

    # determine start, end and lead times
    lead_times = xps[0].fc_lead_times
    print('              lead times:  ', lead_times)
    if start_time is None :
        start_time_ = xps[0].fc_start_times[0]
    else :
        start_time_ = start_time
    if end_time is None :
        end_time_ = xps[0].valid_times['an'][-1]
    else :
        end_time_ = end_time

    # determine which variables should be returned
    if add_vars is None :
        variables = ['obs','lat','lon','level','plevel','time','e_o','bcor']
    else :
        variables = ['obs'] + list(add_vars)

    # initialize output dictionary
    res = {}

    # loop over all times
    ct = to_datetime(start_time_)
    et = to_datetime(end_time_)
    dt = to_timedelta(lead_times[1],units='h') - to_timedelta(lead_times[0],units='h')
    while ct <= et :
        print('PROCESSING ', ct)

        # read ver* files
        vers = []
        for ixp, xp in enumerate(xps) :
            ver_fn = xp.get_filename( 'ver', time_valid=ct, obs_type=obstype )
            if os.path.exists(ver_fn) :
                ver = Ekf(ver_fn,**filter)                
                if ixp == 0 :
                    mts = ver.veri_available('maindet')
                else :
                    mts = common_subset( (mts, ver.veri_available('maindet')) )
                    #if ''.join(mts) != ''.join(ver.veri_available('maindet')) :
                    #    raise ValueError('ERROR: main forecast start times mismatch...')
                print(xp.exp_dir, mts, ver.n_obs())
                vers.append(ver)
            else :
                raise IOError('ERROR: {} is missing...'.format(ver_fn))

        # find common subset of observations
        if n_exps > 1 :
            Ekf.filter_common( vers, filtername='common' )
            #print('common obs: ', vers[0].n_obs(), vers[-1].n_obs(), vers[0].filtername, vers[-1].filtername)

            if True : # test
                for i in range(1,n_exps) :
                    maxerr = np.abs(vers[i].obs()-vers[0].obs()).max()
                    if maxerr > 1e-15 :
                        print('WARNING: Observations are not identical in experiments {} and {}'.format(xps[0].exp_dir,xps[i].exp_dir))

        # store observations and model equivalents
        for mt in mts : # loop over main forecast start times
            lt = ct - to_datetime(mt)            # lead time as timedelta object
            lt_h = lt.days*24 + lt.seconds//3600 # lead time in hours
            print('--storing--> ', ct, '=', mt, '+', lt_h)
            if not mt in res : res[mt] = {}
            if not lt_h in res[mt] : res[mt][lt_h] = {'obs':{},'ver':{}}
            # get header and body variables from first experiment
            for v in variables :
                res[mt][lt_h]['obs'][v] = vers[0].obs(param=v)
            # add model equivalents from each experiment
            for i in range(n_exps) :
                res[mt][lt_h]['ver'][xps[i].exp_dir] = vers[i].maindet(inidate=mt)
            
        print()
        ct += dt

    return res


#-------------------------------------------------------------------------------
if __name__ == "__main__": # ---------------------------------------------------
#-------------------------------------------------------------------------------

    # parse command line arguments
    parser = define_parser()
    args = parser.parse_args()
    
    vd = get_veri_data( args.experiments, obstype=args.obstype, filter='varname={} state=active'.format(args.varname), start_time=args.start_time, end_time=args.end_time )

    # example
    fig, ax = plt.subplots()
    for mt in sorted(list(vd.keys())) :   # main forecast start times
        lts = sorted(list(vd[mt].keys())) # lead times
        t = [ to_datetime(mt) + to_timedelta(lt,units='h') for lt in lts ]
        expids = list( vd[mt][lts[0]]['ver'].keys() )
        for i, expid in enumerate(expids) :            
            ax.plot_date( t, [  np.sqrt(((vd[mt][lt]['ver'][expid] - vd[mt][lt]['obs']['obs'])**2).mean()) \
                                for lt in sorted(list(vd[mt].keys())) ], ['-r','-b','-g','-k'][i], label='expid' )
    ax.xaxis.set_tick_params(rotation=30, labelsize=10)
    fig.savefig('veri.png')

